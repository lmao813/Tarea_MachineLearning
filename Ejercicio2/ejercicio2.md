#  Clasificaci贸n con SVM (Support Vector Machines)    

##  Descripci贸n del ejercicio  
Se estudi贸 el algoritmo de Support Vector Machines (SVM) y se aplic贸 a un problema de clasificaci贸n no lineal usando el conjunto de datos sint茅tico `make_moons`. Se compar贸 el rendimiento de un clasificador SVM con kernel **lineal** frente a uno con kernel **RBF (Radial Basis Function)**, para evidenciar su capacidad de separaci贸n en espacios no linealmente separables.

## 锔 Implementaci贸n  
- Se generaron datos no linealmente separables (`make_moons`) con ruido.
- Se entrenaron dos clasificadores SVM:
  - Uno con kernel `linear`
  - Otro con kernel `rbf`
- Se evaluaron sus predicciones sobre el conjunto de prueba y se graficaron las fronteras de decisi贸n de ambos modelos.

##  Resultados  
- El modelo con kernel **RBF** logr贸 una mayor exactitud que el modelo lineal, dado que los datos no son separables linealmente.
- Se evidenci贸 visualmente la diferencia en la capacidad de cada modelo para trazar una frontera efectiva de decisi贸n.
<img width="590" height="490" alt="image" src="https://github.com/user-attachments/assets/6028f9dc-9d5c-4cb8-a3a0-b7c21ad905df" />
  - Exactitud con SVM Lineal: 0.9000
<img width="590" height="490" alt="image" src="https://github.com/user-attachments/assets/90f243be-e8b3-465e-81a8-160abd2a4c00" />
  - Exactitud con SVM RBF: 0.9667

##  Conceptos clave  
- El **SVM lineal** busca un hiperplano que separe los datos en dos clases con el mayor margen posible.
- El **SVM con kernel RBF** proyecta los datos en un espacio de mayor dimensi贸n donde s铆 pueden ser separados linealmente.
- La elecci贸n del kernel y sus par谩metros (`C`, `gamma`) afecta la flexibilidad y generalizaci贸n del modelo.


##  Observaciones
Este ejercicio permiti贸 visualizar las ventajas de usar kernels no lineales en problemas reales. Tambi茅n se reforz贸 el entendimiento de c贸mo funciona el margen, los vectores de soporte y el efecto de la complejidad del modelo sobre el sobreajuste.
